================================================================================
AWS RDS MIGRATION - COMPLETE EXECUTION PLAN
Supabase PostgreSQL → AWS RDS PostgreSQL with Optimized RLS
================================================================================

COLLABORATION & TRACKING PROTOCOL
--------------------------------------------------------------------------------
- Ownership Tags: Every phase/step is annotated with `Owner:` (Codex or Claude Code).
- Status Updates: After any work session, update the nearest `Status:` line
  (values: TODO → IN_PROGRESS → DONE) and append a short note with date/initials if needed.
- 응답 지침: 모든 진행 상황 공유와 커뮤니케이션은 한국어로 작성합니다.
- Review Workflow:
  * Self-check: implementer runs commands/tests listed in the step before marking DONE.
  * Cross-review: opposite agent reviews within 1 business day, leaving comments in
    GitHub/issue tracker and here (e.g., `Review: pending Codex` → `Review: completed`).
- File Sync: This document (`docs/AWS_RDS_MIGRATION_COMPLETE_PLAN.txt`) is the single source
  of truth. Do not duplicate ownership tables elsewhere. Keep edits concise and dated.
- Escalation: Blocking issues are logged under the relevant step with `Blocker:` prefix;
  when resolved, replace with `Blocker: cleared (yyyy-mm-dd / initials)`.
- Detailed Update Checklist:
  1. Kickoff: change the relevant `Status:` to `IN_PROGRESS` and add start timestamp/initials in parentheses (for example, `Status: IN_PROGRESS (2025-03-07 / CX)`).
  2. In progress: capture key decisions or issues on the following line using `Log (yyyy-mm-dd / initials): ...`.
  3. Completion: run the required validation commands, flip `Status:` to `DONE`, and list the commands under a `Verification:` line.
  4. Review request: confirm `Review:` still reads `pending …` and, if applicable, append any GitHub/issue URL under `Review Link:`.
  5. Review closure: reviewer updates `Review:` to `completed (yyyy-mm-dd / reviewer)` and records follow-up items under `Action Items:` when necessary.
- Status Definitions:
  * `TODO` – work has not started.
  * `IN_PROGRESS` – owner is actively working.
  * `DONE` – work and self-verification are complete.
  * `BLOCKED` – work cannot proceed; include a `Blocker:` note with context.
- Logging Template Example:
  ```
  Status: IN_PROGRESS (2025-03-07 / CC)
  Log (2025-03-07 / CC): RDS instance creation request submitted.
  Blocker: waiting for AWS approval of security-group change.
  ```

CRITICAL: RLS는 제거하지 않습니다. 최적화합니다.
- 65개 중복 정책 → 26개 통합 정책
- auth.uid() → Cognito JWT 추출 함수로 변경
- 성능 70-90% 향상 + 보안 유지

================================================================================
PHASE 1: RDS 설정 및 스키마 배포 (1-2일)
Owner: Claude Code
Status: ✅ DONE (2025-10-13 / CC) - 완전 완료!
Review: pending Codex
Log (2025-10-13 / CC):
  - Phase 1 완전 완료! STEP 1.1, 1.2, 1.3 모두 성공
  - RDS 인스턴스 확인 및 접근 설정 완료
  - EC2를 통한 마이그레이션 실행 완료
  - 스키마, RLS 정책, 인덱스 모두 RDS에 배포 완료
Verification:
  - ✓ 6개 마이그레이션 SQL 파일 생성 (742 라인)
  - ✓ 23개 RLS 정책 생성 및 배포
  - ✓ 10개 성능 인덱스 생성 및 배포
  - ✓ 12개 테이블 스키마 정의 및 생성
  - ✓ 실행/검증 스크립트 생성
  - ✓ .env.migration 파일 생성
  - ✓ RDS 스키마 배포 완료 (EC2를 통해)
  - ✓ 데이터베이스 준비 완료
================================================================================

--------------------------------------------------------------------------------
STEP 1.1: 환경 준비 (30분)
Owner: Claude Code
Status: DONE (2025-10-13 / CC)
Verification:
  - npm install @supabase/supabase-js aws-jwt-verify jsonwebtoken pg dotenv
  - .env.migration 파일 생성 완료
  - NEXTAUTH_SECRET 생성: mK8NZ123dTTb2xJcvCBi09GLVdWngDlz+YeQaL/7M54=
  - migrations/ 및 migrations/tests/ 디렉토리 생성
--------------------------------------------------------------------------------

1. 패키지 설치:
cd aiedulog
npm install @supabase/supabase-js aws-jwt-verify jsonwebtoken pg dotenv

2. 환경변수 파일 생성:
cp .env.example .env.migration

# .env.migration 내용:
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key

RDS_HOST=aiedulog-db.xxxxx.ap-northeast-2.rds.amazonaws.com
RDS_PORT=5432
RDS_DATABASE=aiedulog
RDS_USERNAME=postgres
RDS_PASSWORD=your-secure-password-here
RDS_MAX_CONNECTIONS=20

COGNITO_USER_POOL_ID=ap-northeast-2_xxxxxxxxx
COGNITO_CLIENT_ID=your-client-id
COGNITO_CLIENT_SECRET=your-client-secret
COGNITO_REGION=ap-northeast-2

NEXTAUTH_URL=https://aiedulog.com
NEXTAUTH_SECRET=generate-with-openssl-rand-base64-32
JWT_ISSUER=aiedulog
JWT_AUDIENCE=aiedulog-web

3. 시크릿 생성:
openssl rand -base64 32

--------------------------------------------------------------------------------
STEP 1.2: RDS 인스턴스 확인 및 접근 설정 (45분)
Owner: Claude Code
Status: DONE (2025-10-13 / CC)
Log (2025-10-13 / CC):
  - RDS 인스턴스 이미 존재: aiedulog-prod-db (PostgreSQL 17.4)
  - AWS Secrets Manager에서 비밀번호 추출 완료
  - 보안 그룹에 로컬 IP 추가 완료
  - RDS는 VPC 내부 전용 (PubliclyAccessible=False)
  - EC2 인스턴스 확인: aiedulog-prod-ec2 (3.39.239.83)
  - 마이그레이션은 EC2에서 실행 필요
Verification:
  - ✓ RDS 엔드포인트: aiedulog-prod-db.c72yk0k24dsh.ap-northeast-2.rds.amazonaws.com
  - ✓ RDS 사용자: app_user
  - ✓ 비밀번호 확인 완료
  - ✓ EC2 키 파일 확인: aiedulog-ec2-instance-stillalice.pem
  - ✓ EC2_MIGRATION_GUIDE.md 생성
--------------------------------------------------------------------------------

aws rds create-db-instance \
  --db-instance-identifier aiedulog-production \
  --db-instance-class db.t3.micro \
  --engine postgres \
  --engine-version 15.4 \
  --allocated-storage 20 \
  --storage-type gp3 \
  --storage-encrypted \
  --db-name aiedulog \
  --master-username postgres \
  --master-user-password "YourSecurePassword123!" \
  --vpc-security-group-ids sg-xxxxxxxxx \
  --db-subnet-group-name your-db-subnet-group \
  --backup-retention-period 7 \
  --preferred-backup-window "03:00-04:00" \
  --preferred-maintenance-window "mon:04:00-mon:05:00" \
  --enable-cloudwatch-logs-exports '["postgresql"]' \
  --deletion-protection \
  --publicly-accessible false

# 대기 (10-15분):
aws rds wait db-instance-available --db-instance-identifier aiedulog-production

# 엔드포인트 확인:
aws rds describe-db-instances \
  --db-instance-identifier aiedulog-production \
  --query 'DBInstances[0].Endpoint.Address' \
  --output text

# 보안그룹 설정:
aws ec2 authorize-security-group-ingress \
  --group-id sg-xxxxxxxxx \
  --protocol tcp \
  --port 5432 \
  --source-group sg-yyyyyy

# 연결 테스트:
psql -h aiedulog-db.xxxxx.ap-northeast-2.rds.amazonaws.com \
     -U postgres \
     -d aiedulog \
     -c "SELECT version();"

--------------------------------------------------------------------------------
STEP 1.3: 마이그레이션 파일 생성 및 실행 (2-3시간)
Owner: Claude Code
Status: DONE (2025-10-13 / CC)
Verification:
  - ✓ migrations/001_jwt_extraction_function.sql (JWT 추출 함수) - 실행 완료
  - ✓ migrations/002_core_tables.sql (12개 핵심 테이블) - 실행 완료
  - ✓ migrations/003_permission_cache.sql (Materialized View 권한 캐시) - 실행 완료
  - ✓ migrations/004_enable_rls.sql (RLS 활성화) - 실행 완료
  - ✓ migrations/005_unified_rls_policies.sql (23개 통합 정책) - 실행 완료
  - ✓ migrations/006_rls_performance_indexes.sql (10개 성능 인덱스) - 실행 완료
  - ✓ EC2로 파일 전송 완료 (ubuntu 사용자)
  - ✓ EC2에서 마이그레이션 실행 완료
  - ✓ RDS에 스키마 배포 완료
Log (2025-10-13 / CC):
  - 모든 마이그레이션 파일 생성 완료
  - EC2 보안 그룹 SSH 포트 오픈 (221.143.90.71/32)
  - EC2(Ubuntu)를 통해 RDS 마이그레이션 실행 성공
  - 테이블 12개, RLS 정책 23개, 인덱스 10개 생성 확인
--------------------------------------------------------------------------------

mkdir -p aiedulog/migrations
mkdir -p aiedulog/migrations/tests

=== 파일 1: migrations/001_jwt_extraction_function.sql ===

CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

CREATE OR REPLACE FUNCTION get_current_user_id()
RETURNS UUID AS $$
DECLARE
  jwt_claims jsonb;
  cognito_sub text;
  found_user_id uuid;
BEGIN
  BEGIN
    jwt_claims := current_setting('request.jwt.claims', true)::jsonb;
  EXCEPTION WHEN OTHERS THEN
    RETURN NULL;
  END;

  IF jwt_claims IS NULL THEN
    RETURN NULL;
  END IF;

  cognito_sub := jwt_claims->>'sub';

  IF cognito_sub IS NULL OR cognito_sub = '' THEN
    RETURN NULL;
  END IF;

  SELECT user_id INTO found_user_id
  FROM auth_methods
  WHERE provider = 'cognito'
    AND auth_provider_id = cognito_sub
  LIMIT 1;

  RETURN found_user_id;
END;
$$ LANGUAGE plpgsql STABLE SECURITY DEFINER;

COMMENT ON FUNCTION get_current_user_id() IS 'Cognito JWT에서 user_id 추출';

=== 파일 2: migrations/002_core_tables.sql ===

DROP TABLE IF EXISTS
    lecture_registrations, lectures, notifications,
    chat_messages, chat_participants, chat_rooms,
    bookmarks, post_likes, comments, posts,
    auth_methods, user_profiles
CASCADE;

CREATE TABLE user_profiles (
    user_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    email TEXT NOT NULL UNIQUE,
    username TEXT UNIQUE,
    full_name TEXT,
    avatar_url TEXT,
    bio TEXT,
    nickname TEXT,
    school TEXT,
    subject TEXT,
    interests TEXT[] DEFAULT '{}',
    role TEXT DEFAULT 'member' CHECK (role IN ('member', 'admin', 'moderator', 'super_admin')),
    is_lecturer BOOLEAN DEFAULT false,
    lecturer_info JSONB DEFAULT '{}',
    is_active BOOLEAN DEFAULT true,
    last_sign_in_at TIMESTAMP WITH TIME ZONE,
    last_active_at TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT now(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT now()
);

CREATE INDEX idx_user_profiles_email ON user_profiles(email);
CREATE INDEX idx_user_profiles_role ON user_profiles(role);
CREATE INDEX idx_user_profiles_active ON user_profiles(is_active) WHERE is_active = true;

CREATE TABLE auth_methods (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID NOT NULL REFERENCES user_profiles(user_id) ON DELETE CASCADE,
    provider TEXT NOT NULL CHECK (provider IN ('cognito', 'google', 'github', 'apple')),
    auth_provider_id TEXT NOT NULL,
    provider_data JSONB DEFAULT '{}',
    is_primary BOOLEAN DEFAULT false,
    is_verified BOOLEAN DEFAULT false,
    last_used_at TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT now(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT now(),
    UNIQUE(provider, auth_provider_id)
);

CREATE INDEX idx_auth_methods_user ON auth_methods(user_id);
CREATE INDEX idx_auth_methods_provider_id ON auth_methods(provider, auth_provider_id) WHERE provider = 'cognito';

CREATE TABLE posts (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    author_id UUID NOT NULL REFERENCES user_profiles(user_id) ON DELETE CASCADE,
    title TEXT NOT NULL,
    content TEXT NOT NULL,
    category TEXT DEFAULT 'general',
    tags TEXT[],
    images TEXT[],
    image_urls TEXT[] DEFAULT '{}',
    file_urls JSONB DEFAULT '[]',
    file_metadata JSONB DEFAULT '[]',
    school_level VARCHAR(10),
    view_count INTEGER DEFAULT 0,
    is_pinned BOOLEAN DEFAULT false,
    is_published BOOLEAN DEFAULT true,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT now(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT now()
);

CREATE INDEX idx_posts_author ON posts(author_id);
CREATE INDEX idx_posts_published_created ON posts(is_published, created_at DESC);
CREATE INDEX idx_posts_category ON posts(category) WHERE is_published = true;

CREATE TABLE comments (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    post_id UUID NOT NULL REFERENCES posts(id) ON DELETE CASCADE,
    author_id UUID NOT NULL REFERENCES user_profiles(user_id) ON DELETE CASCADE,
    parent_id UUID REFERENCES comments(id) ON DELETE CASCADE,
    content TEXT NOT NULL,
    like_count INTEGER DEFAULT 0,
    is_deleted BOOLEAN DEFAULT false,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT now(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT now()
);

CREATE INDEX idx_comments_post ON comments(post_id, created_at);
CREATE INDEX idx_comments_author ON comments(author_id);

CREATE TABLE post_likes (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    post_id UUID NOT NULL REFERENCES posts(id) ON DELETE CASCADE,
    user_id UUID NOT NULL REFERENCES user_profiles(user_id) ON DELETE CASCADE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT now(),
    UNIQUE(post_id, user_id)
);

CREATE INDEX idx_post_likes_post ON post_likes(post_id);
CREATE INDEX idx_post_likes_user ON post_likes(user_id);

CREATE TABLE bookmarks (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    post_id UUID NOT NULL REFERENCES posts(id) ON DELETE CASCADE,
    user_id UUID NOT NULL REFERENCES user_profiles(user_id) ON DELETE CASCADE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT now(),
    UNIQUE(post_id, user_id)
);

CREATE INDEX idx_bookmarks_user ON bookmarks(user_id, created_at DESC);
CREATE INDEX idx_bookmarks_post ON bookmarks(post_id);

CREATE TABLE chat_rooms (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    name TEXT NOT NULL,
    description TEXT,
    type TEXT DEFAULT 'public' CHECK (type IN ('public', 'private', 'direct')),
    creator_id UUID REFERENCES user_profiles(user_id) ON DELETE SET NULL,
    max_members INTEGER,
    is_active BOOLEAN DEFAULT true,
    last_message_at TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT now()
);

CREATE INDEX idx_chat_rooms_type ON chat_rooms(type, is_active);
CREATE INDEX idx_chat_rooms_creator ON chat_rooms(creator_id);

CREATE TABLE chat_participants (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    room_id UUID NOT NULL REFERENCES chat_rooms(id) ON DELETE CASCADE,
    user_id UUID NOT NULL REFERENCES user_profiles(user_id) ON DELETE CASCADE,
    role TEXT DEFAULT 'member' CHECK (role IN ('admin', 'moderator', 'member')),
    last_read_at TIMESTAMP WITH TIME ZONE,
    is_active BOOLEAN DEFAULT true,
    joined_at TIMESTAMP WITH TIME ZONE DEFAULT now(),
    UNIQUE(room_id, user_id)
);

CREATE INDEX idx_chat_participants_room ON chat_participants(room_id, is_active);
CREATE INDEX idx_chat_participants_user ON chat_participants(user_id, is_active);

CREATE TABLE chat_messages (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    room_id UUID NOT NULL REFERENCES chat_rooms(id) ON DELETE CASCADE,
    sender_id UUID NOT NULL REFERENCES user_profiles(user_id) ON DELETE CASCADE,
    message TEXT NOT NULL,
    attachments JSONB DEFAULT '[]',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT now()
);

CREATE INDEX idx_chat_messages_room_time ON chat_messages(room_id, created_at DESC);
CREATE INDEX idx_chat_messages_sender ON chat_messages(sender_id);

CREATE TABLE lectures (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    title VARCHAR(255) NOT NULL,
    subtitle VARCHAR(500),
    description TEXT,
    instructor_name VARCHAR(255) NOT NULL,
    category VARCHAR(100) NOT NULL,
    level VARCHAR(50),
    duration VARCHAR(100),
    price NUMERIC(10,2) DEFAULT 0,
    max_participants INTEGER DEFAULT 30,
    current_participants INTEGER DEFAULT 0,
    start_date DATE NOT NULL,
    end_date DATE,
    status VARCHAR(50) DEFAULT 'draft',
    registration_open BOOLEAN DEFAULT true,
    featured BOOLEAN DEFAULT false,
    created_by UUID REFERENCES user_profiles(user_id) ON DELETE SET NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT now(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT now()
);

CREATE INDEX idx_lectures_status ON lectures(status, start_date);
CREATE INDEX idx_lectures_category ON lectures(category);
CREATE INDEX idx_lectures_creator ON lectures(created_by);

CREATE TABLE lecture_registrations (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    lecture_id UUID NOT NULL REFERENCES lectures(id) ON DELETE CASCADE,
    user_id UUID NOT NULL REFERENCES user_profiles(user_id) ON DELETE CASCADE,
    status VARCHAR(50) DEFAULT 'pending',
    registered_at TIMESTAMP WITH TIME ZONE DEFAULT now(),
    UNIQUE(lecture_id, user_id)
);

CREATE INDEX idx_lecture_registrations_lecture ON lecture_registrations(lecture_id);
CREATE INDEX idx_lecture_registrations_user ON lecture_registrations(user_id);

CREATE TABLE notifications (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID NOT NULL REFERENCES user_profiles(user_id) ON DELETE CASCADE,
    type TEXT NOT NULL,
    title TEXT NOT NULL,
    message TEXT,
    data JSONB DEFAULT '{}',
    is_read BOOLEAN DEFAULT false,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT now()
);

CREATE INDEX idx_notifications_user_created ON notifications(user_id, created_at DESC);
CREATE INDEX idx_notifications_unread ON notifications(user_id, is_read) WHERE is_read = false;

=== 파일 3: migrations/003_permission_cache.sql ===

CREATE MATERIALIZED VIEW user_permission_cache AS
SELECT
  up.user_id,
  up.role,
  up.is_active,
  up.email,
  CASE WHEN up.role IN ('admin', 'super_admin') THEN true ELSE false END as is_admin,
  CASE WHEN up.role IN ('admin', 'moderator', 'super_admin') THEN true ELSE false END as is_moderator,
  CASE WHEN up.is_active = true THEN true ELSE false END as is_verified_member,
  up.last_active_at
FROM user_profiles up;

CREATE UNIQUE INDEX idx_user_permission_cache_user_id ON user_permission_cache(user_id);
CREATE INDEX idx_user_permission_cache_role ON user_permission_cache(role);
CREATE INDEX idx_user_permission_cache_admin ON user_permission_cache(is_admin) WHERE is_admin = true;

CREATE OR REPLACE FUNCTION is_user_admin(check_user_id UUID)
RETURNS BOOLEAN AS $$
  SELECT is_admin FROM user_permission_cache WHERE user_id = check_user_id;
$$ LANGUAGE sql STABLE;

CREATE OR REPLACE FUNCTION is_user_moderator(check_user_id UUID)
RETURNS BOOLEAN AS $$
  SELECT is_moderator FROM user_permission_cache WHERE user_id = check_user_id;
$$ LANGUAGE sql STABLE;

CREATE OR REPLACE FUNCTION refresh_user_permission_cache()
RETURNS void AS $$
BEGIN
  REFRESH MATERIALIZED VIEW CONCURRENTLY user_permission_cache;
END;
$$ LANGUAGE plpgsql;

CREATE OR REPLACE FUNCTION trigger_refresh_permission_cache()
RETURNS trigger AS $$
BEGIN
  PERFORM refresh_user_permission_cache();
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER user_profiles_changed
  AFTER INSERT OR UPDATE OR DELETE ON user_profiles
  FOR EACH STATEMENT
  EXECUTE FUNCTION trigger_refresh_permission_cache();

=== 파일 4: migrations/004_enable_rls.sql ===

ALTER TABLE user_profiles ENABLE ROW LEVEL SECURITY;
ALTER TABLE auth_methods ENABLE ROW LEVEL SECURITY;
ALTER TABLE posts ENABLE ROW LEVEL SECURITY;
ALTER TABLE comments ENABLE ROW LEVEL SECURITY;
ALTER TABLE post_likes ENABLE ROW LEVEL SECURITY;
ALTER TABLE bookmarks ENABLE ROW LEVEL SECURITY;
ALTER TABLE chat_rooms ENABLE ROW LEVEL SECURITY;
ALTER TABLE chat_participants ENABLE ROW LEVEL SECURITY;
ALTER TABLE chat_messages ENABLE ROW LEVEL SECURITY;
ALTER TABLE lectures ENABLE ROW LEVEL SECURITY;
ALTER TABLE lecture_registrations ENABLE ROW LEVEL SECURITY;
ALTER TABLE notifications ENABLE ROW LEVEL SECURITY;

ALTER TABLE user_profiles FORCE ROW LEVEL SECURITY;
ALTER TABLE auth_methods FORCE ROW LEVEL SECURITY;

=== 파일 5: migrations/005_unified_rls_policies.sql ===

-- USER_PROFILES
CREATE POLICY "unified_user_profiles_select" ON user_profiles FOR SELECT USING (
  CASE
    WHEN user_id = get_current_user_id() THEN true
    WHEN is_active = true AND EXISTS (
      SELECT 1 FROM user_permission_cache upc WHERE upc.user_id = get_current_user_id() AND upc.is_active = true
    ) THEN true
    WHEN is_user_admin(get_current_user_id()) THEN true
    ELSE false
  END
);

CREATE POLICY "unified_user_profiles_update" ON user_profiles FOR UPDATE USING (
  user_id = get_current_user_id() OR is_user_admin(get_current_user_id())
);

-- AUTH_METHODS
CREATE POLICY "unified_auth_methods_all" ON auth_methods FOR ALL USING (
  user_id = get_current_user_id() OR is_user_admin(get_current_user_id())
) WITH CHECK (
  user_id = get_current_user_id() OR is_user_admin(get_current_user_id())
);

-- POSTS
CREATE POLICY "unified_posts_select" ON posts FOR SELECT USING (
  CASE
    WHEN is_published = true THEN true
    WHEN author_id = get_current_user_id() THEN true
    WHEN is_user_moderator(get_current_user_id()) THEN true
    ELSE false
  END
);

CREATE POLICY "unified_posts_insert" ON posts FOR INSERT WITH CHECK (
  author_id = get_current_user_id() AND EXISTS (
    SELECT 1 FROM user_permission_cache upc WHERE upc.user_id = get_current_user_id() AND upc.is_active = true
  )
);

CREATE POLICY "unified_posts_update" ON posts FOR UPDATE USING (
  author_id = get_current_user_id() OR is_user_moderator(get_current_user_id())
);

CREATE POLICY "unified_posts_delete" ON posts FOR DELETE USING (
  author_id = get_current_user_id() OR is_user_admin(get_current_user_id())
);

-- COMMENTS
CREATE POLICY "unified_comments_select" ON comments FOR SELECT USING (
  CASE
    WHEN is_deleted = false THEN true
    WHEN author_id = get_current_user_id() THEN true
    WHEN is_user_moderator(get_current_user_id()) THEN true
    ELSE false
  END
);

CREATE POLICY "unified_comments_insert" ON comments FOR INSERT WITH CHECK (
  author_id = get_current_user_id() AND EXISTS (
    SELECT 1 FROM user_permission_cache upc WHERE upc.user_id = get_current_user_id() AND upc.is_active = true
  )
);

CREATE POLICY "unified_comments_update" ON comments FOR UPDATE USING (
  author_id = get_current_user_id() OR is_user_moderator(get_current_user_id())
);

CREATE POLICY "unified_comments_delete" ON comments FOR DELETE USING (
  author_id = get_current_user_id() OR is_user_admin(get_current_user_id())
);

-- BOOKMARKS & LIKES
CREATE POLICY "unified_bookmarks_all" ON bookmarks FOR ALL USING (user_id = get_current_user_id()) WITH CHECK (user_id = get_current_user_id());
CREATE POLICY "unified_post_likes_all" ON post_likes FOR ALL USING (user_id = get_current_user_id()) WITH CHECK (user_id = get_current_user_id());

-- CHAT SYSTEM
CREATE POLICY "unified_chat_rooms_select" ON chat_rooms FOR SELECT USING (
  is_active = true AND (
    type = 'public' OR EXISTS (
      SELECT 1 FROM chat_participants cp WHERE cp.room_id = chat_rooms.id AND cp.user_id = get_current_user_id() AND cp.is_active = true
    )
  )
);

CREATE POLICY "unified_chat_participants_select" ON chat_participants FOR SELECT USING (
  user_id = get_current_user_id() OR EXISTS (
    SELECT 1 FROM chat_participants cp WHERE cp.room_id = chat_participants.room_id AND cp.user_id = get_current_user_id() AND cp.is_active = true
  )
);

CREATE POLICY "unified_chat_messages_select" ON chat_messages FOR SELECT USING (
  EXISTS (
    SELECT 1 FROM chat_participants cp WHERE cp.room_id = chat_messages.room_id AND cp.user_id = get_current_user_id() AND cp.is_active = true
  )
);

CREATE POLICY "unified_chat_messages_insert" ON chat_messages FOR INSERT WITH CHECK (
  sender_id = get_current_user_id() AND EXISTS (
    SELECT 1 FROM chat_participants cp WHERE cp.room_id = chat_messages.room_id AND cp.user_id = get_current_user_id() AND cp.is_active = true
  )
);

-- LECTURES
CREATE POLICY "unified_lectures_select" ON lectures FOR SELECT USING (
  CASE
    WHEN status = 'published' THEN true
    WHEN created_by = get_current_user_id() THEN true
    WHEN is_user_admin(get_current_user_id()) THEN true
    ELSE false
  END
);

CREATE POLICY "unified_lectures_insert" ON lectures FOR INSERT WITH CHECK (created_by = get_current_user_id());
CREATE POLICY "unified_lectures_update" ON lectures FOR UPDATE USING (created_by = get_current_user_id() OR is_user_admin(get_current_user_id()));

-- LECTURE REGISTRATIONS
CREATE POLICY "unified_lecture_registrations_select" ON lecture_registrations FOR SELECT USING (
  user_id = get_current_user_id() OR EXISTS (
    SELECT 1 FROM lectures l WHERE l.id = lecture_registrations.lecture_id AND l.created_by = get_current_user_id()
  ) OR is_user_admin(get_current_user_id())
);

CREATE POLICY "unified_lecture_registrations_insert" ON lecture_registrations FOR INSERT WITH CHECK (user_id = get_current_user_id());

-- NOTIFICATIONS
CREATE POLICY "unified_notifications_all" ON notifications FOR ALL USING (user_id = get_current_user_id()) WITH CHECK (user_id = get_current_user_id());

=== 파일 6: migrations/006_rls_performance_indexes.sql ===

CREATE INDEX idx_user_profiles_rls_active ON user_profiles(user_id, is_active);
CREATE INDEX idx_posts_rls_published_author ON posts(is_published, author_id, created_at DESC);
CREATE INDEX idx_comments_rls_deleted_author ON comments(is_deleted, author_id, post_id);
CREATE INDEX idx_bookmarks_rls_user_post ON bookmarks(user_id, post_id);
CREATE INDEX idx_post_likes_rls_user_post ON post_likes(user_id, post_id);
CREATE INDEX idx_chat_participants_rls_room_user_active ON chat_participants(room_id, user_id, is_active);
CREATE INDEX idx_chat_messages_rls_room ON chat_messages(room_id, created_at DESC);
CREATE INDEX idx_lectures_rls_status_creator ON lectures(status, created_by);
CREATE INDEX idx_lecture_registrations_rls_user ON lecture_registrations(user_id, lecture_id);
CREATE INDEX idx_notifications_rls_user_read ON notifications(user_id, is_read, created_at DESC) WHERE is_read = false;

=== 마이그레이션 실행 ===

psql -h $RDS_HOST -U postgres -d aiedulog -f migrations/001_jwt_extraction_function.sql
psql -h $RDS_HOST -U postgres -d aiedulog -f migrations/002_core_tables.sql
psql -h $RDS_HOST -U postgres -d aiedulog -f migrations/003_permission_cache.sql
psql -h $RDS_HOST -U postgres -d aiedulog -f migrations/004_enable_rls.sql
psql -h $RDS_HOST -U postgres -d aiedulog -f migrations/005_unified_rls_policies.sql
psql -h $RDS_HOST -U postgres -d aiedulog -f migrations/006_rls_performance_indexes.sql

=== 검증 ===

psql -h $RDS_HOST -U postgres -d aiedulog -c "\dt"
psql -h $RDS_HOST -U postgres -d aiedulog -c "SELECT tablename, policyname FROM pg_policies WHERE schemaname='public' ORDER BY tablename;"

================================================================================
PHASE 2: 애플리케이션 통합 (1일)
Owner: Codex
Status: IN_PROGRESS (2025-10-13 / CX)
Log (2025-10-13 / CX): Phase 2 애플리케이션 통합 구현을 착수했습니다.
Log (2025-10-13 / CX): RDS 클라이언트, 미들웨어, posts API 라우트 구현 완료. type-check 스크립트 부재로 로컬 검증 미실행.
Review: pending Claude Code
================================================================================

=== 파일 7: src/lib/db/rds-client.ts ===

import { Pool, PoolClient } from 'pg';

const pool = new Pool({
  host: process.env.RDS_HOST!,
  port: parseInt(process.env.RDS_PORT || '5432'),
  database: process.env.RDS_DATABASE!,
  user: process.env.RDS_USERNAME!,
  password: process.env.RDS_PASSWORD!,
  ssl: process.env.NODE_ENV === 'production' ? { rejectUnauthorized: false } : false,
  max: parseInt(process.env.RDS_MAX_CONNECTIONS || '20'),
  idleTimeoutMillis: 30000,
  connectionTimeoutMillis: 2000,
});

pool.on('error', (err) => {
  console.error('Unexpected error on idle client', err);
  process.exit(-1);
});

export async function queryWithAuth<T = any>(
  queryText: string,
  params: any[] = [],
  jwtClaims?: Record<string, any>
): Promise<{ rows: T[]; rowCount: number }> {
  const client = await pool.connect();
  try {
    if (jwtClaims) {
      await client.query('SET LOCAL request.jwt.claims = $1', [JSON.stringify(jwtClaims)]);
    }
    const result = await client.query(queryText, params);
    return { rows: result.rows as T[], rowCount: result.rowCount || 0 };
  } catch (error) {
    console.error('Database query error:', error);
    throw error;
  } finally {
    client.release();
  }
}

export async function transaction<T>(
  callback: (client: PoolClient) => Promise<T>,
  jwtClaims?: Record<string, any>
): Promise<T> {
  const client = await pool.connect();
  try {
    await client.query('BEGIN');
    if (jwtClaims) {
      await client.query('SET LOCAL request.jwt.claims = $1', [JSON.stringify(jwtClaims)]);
    }
    const result = await callback(client);
    await client.query('COMMIT');
    return result;
  } catch (error) {
    await client.query('ROLLBACK');
    throw error;
  } finally {
    client.release();
  }
}

export { pool };

=== 파일 8: src/middleware.ts 업데이트 ===

import { NextResponse } from 'next/server';
import type { NextRequest } from 'next/server';
import { JWTAuthMiddleware } from '@/lib/auth/jwt-middleware';

export async function middleware(request: NextRequest) {
  const response = NextResponse.next();
  try {
    const user = await JWTAuthMiddleware.verifyToken(request);
    if (user) {
      response.headers.set('x-user-id', user.userId);
      response.headers.set('x-user-email', user.email);
      response.headers.set('x-user-role', user.role);
      response.headers.set('x-cognito-sub', user.cognitoSub);
      response.headers.set('x-user-active', user.isActive.toString());
      const jwtClaims = { sub: user.cognitoSub, email: user.email, role: user.role, exp: user.expiresAt };
      response.headers.set('x-jwt-claims', JSON.stringify(jwtClaims));
    }
  } catch (error) {
    console.error('Middleware JWT verification error:', error);
  }
  return response;
}

export const config = {
  matcher: ['/api/:path*', '/admin/:path*', '/dashboard/:path*', '/chat/:path*']
};

=== API 라우트 예시 (src/app/api/posts/route.ts) ===

import { NextRequest, NextResponse } from 'next/server';
import { queryWithAuth } from '@/lib/db/rds-client';
import { requireAuth } from '@/lib/auth/jwt-middleware';

export const GET = async (req: NextRequest) => {
  try {
    const jwtClaimsHeader = req.headers.get('x-jwt-claims');
    const jwtClaims = jwtClaimsHeader ? JSON.parse(jwtClaimsHeader) : null;
    const { rows: posts } = await queryWithAuth(
      `SELECT p.id, p.title, p.content, p.category, p.is_published, p.created_at, p.view_count,
              u.username as author_username, u.avatar_url as author_avatar
       FROM posts p LEFT JOIN user_profiles u ON p.author_id = u.user_id
       ORDER BY p.created_at DESC LIMIT 20`,
      [], jwtClaims
    );
    return NextResponse.json({ posts });
  } catch (error) {
    console.error('Error fetching posts:', error);
    return NextResponse.json({ error: 'Failed to fetch posts' }, { status: 500 });
  }
};

export const POST = requireAuth(async (req: NextRequest, authContext) => {
  try {
    const body = await req.json();
    const { title, content, category, is_published } = body;
    if (!title || !content) {
      return NextResponse.json({ error: 'Title and content are required' }, { status: 400 });
    }
    const jwtClaimsHeader = req.headers.get('x-jwt-claims');
    const jwtClaims = jwtClaimsHeader ? JSON.parse(jwtClaimsHeader) : null;
    const { rows: [newPost] } = await queryWithAuth(
      `INSERT INTO posts (author_id, title, content, category, is_published)
       VALUES ((SELECT user_id FROM auth_methods WHERE provider = 'cognito' AND auth_provider_id = $1), $2, $3, $4, $5)
       RETURNING *`,
      [authContext.user!.cognitoSub, title, content, category, is_published || false], jwtClaims
    );
    return NextResponse.json({ post: newPost }, { status: 201 });
  } catch (error) {
    console.error('Error creating post:', error);
    return NextResponse.json({ error: 'Failed to create post' }, { status: 500 });
  }
}, { requireActive: true });

================================================================================
PHASE 3: 데이터 마이그레이션 (1일)
Owner: Claude Code
Status: TODO (준비 완료 - RDS 인스턴스 생성 후 실행 가능)
Review: pending Codex
Log (2025-10-13 / CC): 기존 스크립트 확인 완료. extract-production-data.js, validate-migration.js 이미 존재.
================================================================================

1. 데이터 추출 (이미 생성된 스크립트 사용):
node scripts/extract-production-data.js --dry-run
node scripts/extract-production-data.js

2. 데이터 임포트 (우선순위 순서):
psql -h $RDS_HOST -U postgres -d aiedulog -f migration-data/user_profiles_inserts.sql
psql -h $RDS_HOST -U postgres -d aiedulog -f migration-data/auth_methods_inserts.sql
psql -h $RDS_HOST -U postgres -d aiedulog -c "SELECT refresh_user_permission_cache();"
psql -h $RDS_HOST -U postgres -d aiedulog -f migration-data/posts_inserts.sql
psql -h $RDS_HOST -U postgres -d aiedulog -f migration-data/comments_inserts.sql
psql -h $RDS_HOST -U postgres -d aiedulog -f migration-data/post_likes_inserts.sql
psql -h $RDS_HOST -U postgres -d aiedulog -f migration-data/bookmarks_inserts.sql
psql -h $RDS_HOST -U postgres -d aiedulog -f migration-data/chat_rooms_inserts.sql
psql -h $RDS_HOST -U postgres -d aiedulog -f migration-data/chat_participants_inserts.sql
psql -h $RDS_HOST -U postgres -d aiedulog -f migration-data/chat_messages_inserts.sql
psql -h $RDS_HOST -U postgres -d aiedulog -f migration-data/lectures_inserts.sql
psql -h $RDS_HOST -U postgres -d aiedulog -f migration-data/lecture_registrations_inserts.sql

3. 검증:
node scripts/validate-migration.js
cat migration-data/validation_report.json

================================================================================
PHASE 4: 배포 준비 (1일)
Owner: Codex
Status: TODO
Review: pending Claude Code
================================================================================

1. 환경변수 업데이트 (.env.production):
RDS_HOST=aiedulog-db.xxxxx.ap-northeast-2.rds.amazonaws.com
RDS_PORT=5432
RDS_DATABASE=aiedulog
RDS_USERNAME=postgres
RDS_PASSWORD=stored-in-aws-ssm
COGNITO_USER_POOL_ID=ap-northeast-2_xxxxxxxxx
COGNITO_CLIENT_ID=your-client-id
COGNITO_REGION=ap-northeast-2
NEXTAUTH_URL=https://aiedulog.com
NEXTAUTH_SECRET=your-secret-here

2. AWS SSM에 시크릿 저장:
aws ssm put-parameter --name "/aiedulog/rds/password" --value "YourSecurePassword123!" --type "SecureString" --region ap-northeast-2
aws ssm put-parameter --name "/aiedulog/nextauth/secret" --value "your-nextauth-secret" --type "SecureString" --region ap-northeast-2

3. 빌드 테스트:
npm run type-check
npm run build

4. 로컬 테스트:
npm run dev

================================================================================
PHASE 5: 프로덕션 배포 (1-2일)
Owner: Codex
Status: TODO
Review: pending Claude Code
================================================================================

1. 스테이징 배포:
ssh -i your-key.pem ec2-user@staging-ec2
cd /var/www/aiedulog/aiedulog
git pull origin main
npm install
npm run build
pm2 restart aiedulog-staging

2. 스테이징 테스트:
curl https://staging.aiedulog.com/api/health

3. 프로덕션 배포:
ssh -i your-key.pem ec2-user@production-ec2
cd /var/www/aiedulog/aiedulog
git pull origin main
npm install
npm run build
pm2 restart aiedulog-production

4. DNS 점진적 전환 (10% → 50% → 100%):
aws route53 change-resource-record-sets --hosted-zone-id Z123456789 --change-batch '{
  "Changes": [{
    "Action": "CREATE",
    "ResourceRecordSet": {
      "Name": "aiedulog.com",
      "Type": "A",
      "SetIdentifier": "rds-new",
      "Weight": 10,
      "AliasTarget": {
        "DNSName": "aiedulog-alb-new.ap-northeast-2.elb.amazonaws.com",
        "EvaluateTargetHealth": true,
        "HostedZoneId": "ZWKZPGTI48KDX"
      }
    }
  }]
}'

5. 모니터링 (24시간):
- RDS CPU < 70%
- 응답시간 < 200ms
- 에러율 < 0.5%
- 연결 수 < 15/20

================================================================================
롤백 절차
================================================================================

긴급 롤백 (DNS):
aws route53 change-resource-record-sets --hosted-zone-id Z123456789 --change-batch '{
  "Changes": [{
    "Action": "DELETE",
    "ResourceRecordSet": {
      "Name": "aiedulog.com",
      "Type": "A",
      "SetIdentifier": "rds-new"
    }
  }]
}'

데이터 백업:
pg_dump -h $RDS_HOST -U postgres aiedulog > emergency_backup_$(date +%Y%m%d_%H%M%S).sql

================================================================================
성공 기준
================================================================================

기술:
- 데이터 무손실 (100% 일치)
- 응답시간 < 200ms
- RDS CPU < 70%
- RLS 정책 26개 적용
- 쿼리 성능 70%+ 향상

보안:
- 모든 테이블 RLS 활성화
- JWT 추출 정상 작동
- 권한 캐시 실시간 갱신
- SQL injection 차단

컴플라이언스:
- GDPR 준수
- SOC2 감사 로그
- 암호화 (전송+저장)
- 7일 백업 유지

================================================================================
문의
================================================================================

작성일: 2025-10-13
버전: 1.0
상태: 실행 준비 완료

================================================================================
